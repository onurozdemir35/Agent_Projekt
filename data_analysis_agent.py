# ğŸ“¦ Notwendige Bibliotheken importieren
import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from smolagents import InferenceClientModel, CodeAgent
from huggingface_hub import login

# ğŸ”‘ HuggingFace-Token laden und anmelden
login(os.getenv("HF_TOKEN"))

# ğŸ§  LLM-Modell mit Inference API initialisieren
model = InferenceClientModel("meta-llama/Llama-3.1-70B-Instruct")

# ğŸ¤– Agent definieren mit erlaubten Bibliotheken
agent = CodeAgent(
    tools=[],
    model=model,
    additional_authorized_imports=[
        "numpy",
        "pandas",
        "matplotlib.pyplot",
        "seaborn"
    ]
)

# ğŸ“ Sicherstellen, dass der Ausgabeordner existiert
os.makedirs("figures", exist_ok=True)

# ğŸ““ ZusÃ¤tzliche Notizen (z.B. Beschreibung der Spalten)
additional_notes = """
### Variablenbeschreibung:
- 'company': Name des Unternehmens
- 'concept': Finanzkennzahl (z.B. Umsatz, Ausgaben, Eigenkapital)
- Spalten im Format '2024-03-31': stellen Quartalsdaten dar
- Diese Datei enthÃ¤lt Finanzergebnisse verschiedener Unternehmen Ã¼ber mehrere Quartale hinweg.
"""

# ğŸ“£ Benutzerinteraktion â€“ Eingabeaufforderung
print("ğŸ” Bitte gib deinen Analyseauftrag ein (z.B. 'Vergleiche die Verbindlichkeiten von Apple und Microsoft im Jahr 2024.'):\n")
user_prompt = input("> ")

# ğŸƒ Agent ausfÃ¼hren mit Analyseauftrag
antwort = agent.run(
    user_prompt,
    additional_args={
        "source_file": "all_company_financials.csv",
        "additional_notes": additional_notes
    }
)

# ğŸ–¨ Ergebnis anzeigen
print("\nğŸ“Š Analyseergebnis:\n")
print(antwort)